{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Weimw/movielens-project/blob/main/CS224w_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Packages and Libraries"
      ],
      "metadata": {
        "id": "aO6HhJV4NsX6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxoenua1-u5r"
      },
      "source": [
        "# Install required packages.\n",
        "%%capture\n",
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import structured_negative_sampling"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing"
      ],
      "metadata": {
        "id": "sXnpUp2yNqzH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRC_IazQ4Oj",
        "outputId": "a43ac47b-ed3d-4f47-9160-b17d49886ad1"
      },
      "source": [
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` data connects users (as given by `userId`) and movies (as given by `movieId`). We first want to create a mapping that maps entry IDs to a consecutive value in the range `{ 0, ..., num_rows - 1 }`. This is very helpful because it will make the adjency matrix as compact as possible. We then create an `edge_index` which is of shape `[2, num_ratings]` from `ratings.csv`. The first row represents the mapped `userId` and the second row represents the mapped `movieId`. A specific column represents a connection (i.e rating) between a user and a movie. The `edge_index` tensor is very important when propagating the messages along the graph network. "
      ],
      "metadata": {
        "id": "S0bzq0x6QC3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(movie_path: str, rating_path: str): \n",
        "  '''\n",
        "    Args:\n",
        "         movie_path (str): A string representing the file path to the movies dataset.\n",
        "         rating_path (str): A string representing the file path to the ratings dataset.\n",
        "    \n",
        "    Returns:\n",
        "         edge_index (torch.Tensor): the indices of edges in the adjacency matrix for the ratings dataset.\n",
        "         num_users (int): number of unique users in the ratings dataset.\n",
        "         num_movies (int): number of unique movies in the ratings dataset.\n",
        "  '''\n",
        "  # load movies and ratings dataset\n",
        "  movie_df = pd.read_csv(movie_path, index_col = 'movieId')\n",
        "  rating_df = pd.read_csv(rating_path, index_col = 'userId') \n",
        "\n",
        "  # create mapping to continous range\n",
        "  movie_mapping = {idx: i for i, idx in enumerate(movie_df.index.unique())}\n",
        "  user_mapping = {idx: i for i, idx in enumerate(rating_df.index.unique())}\n",
        "  num_users, num_movies = len(rating_df.index.unique()), len(movie_df.index.unique())\n",
        "\n",
        "  rating_df = pd.read_csv(rating_path)\n",
        "  edge_index = None\n",
        "  users = [user_mapping[idx] for idx in rating_df['userId']]\n",
        "  movies = [movie_mapping[idx] for idx in rating_df['movieId']]\n",
        "\n",
        "  # filter for edges with a high rating\n",
        "  ratings = rating_df['rating'].values\n",
        "  recommend_bool = torch.from_numpy(ratings).view(-1, 1).to(torch.long) >= 4\n",
        "\n",
        "  edge_index = [[],[]]\n",
        "  for i in range(recommend_bool.shape[0]):\n",
        "    if recommend_bool[i]:\n",
        "      edge_index[0].append(users[i])\n",
        "      edge_index[1].append(movies[i])\n",
        "    \n",
        "  edge_index = torch.tensor(edge_index)\n",
        "  return edge_index, num_users, num_movies"
      ],
      "metadata": {
        "id": "mLEBcsyv5abc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index, num_users, num_movies = preprocessing(movie_path, rating_path)"
      ],
      "metadata": {
        "id": "lm-VDQZA_GAP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then split the whole dataset into train/val/test sets. The split is conducted on edge level. To be more specifc, we will split the whole dataset into 80/10/10 by random, so that each set will have a subset of `edge_index`."
      ],
      "metadata": {
        "id": "HVRWWdhbRqhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_ratings = edge_index.shape[1]\n",
        "rating_indices = np.arange(num_ratings)\n",
        "\n",
        "indices_train, indices_val_test = train_test_split(rating_indices, test_size = 0.2, random_state = 42)\n",
        "indices_val, indices_test = train_test_split(indices_val_test, test_size = 0.5, random_state = 42)\n",
        "\n",
        "# slice the whole dataset by split indices, then convert to SparseTensor for later training\n",
        "def generate_edge(edge_indices: np.ndarray):\n",
        "  '''\n",
        "  Args:\n",
        "      edge_indices (np.ndarray): An array representing the indices of edges in the dataset.\n",
        "\n",
        "  Returns:\n",
        "      sub_edge_index (torch.Tensor): indices of edges in the specified subset.\n",
        "      edge_index_sparse (SparseTensor): A sparse tensor representing the adjacency matrix for the subset of edges.\n",
        "  '''\n",
        "  sub_edge_index = edge_index[:, edge_indices]\n",
        "  num_nodes = num_users + num_movies\n",
        "  edge_index_sparse = SparseTensor(row = sub_edge_index[0],\n",
        "                                   col = sub_edge_index[1],\n",
        "                                   sparse_sizes = (num_nodes, num_nodes))\n",
        "  return sub_edge_index, edge_index_sparse\n",
        "\n",
        "train_edge_index, train_sparse_edge_index = generate_edge(indices_train)\n",
        "val_edge_index, val_sparse_edge_index = generate_edge(indices_val)\n",
        "test_edge_index, test_sparse_edge_index = generate_edge(indices_test)"
      ],
      "metadata": {
        "id": "d9op9aVbTFIf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In training process, we will use mini-batch strategy and sample several positive edges and negative edges within each batch. A positive edge is defined as observed/training user-item interactions. During training, we want to penalize those negative edges by assigning larger loss to them. We will utilize the `structured_negative_sampling` function in PyG, which samples a negative edge for every positive edge in the graph, given by `edge_index`."
      ],
      "metadata": {
        "id": "tvZpaxT_aFCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "samples a negative edge :obj:`(i,k)` for every positive edge :obj:`(i,j)` in the \n",
        "graph given by :attr:`edge_index`, and returns it as a tuple of the form :obj:`(i,j,k)`.\n",
        "'''\n",
        "edges = structured_negative_sampling(train_edge_index)\n",
        "edges = torch.stack(edges, dim=0)\n",
        "edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uxt8LxCnkE7",
        "outputId": "610f506b-620b-4113-8441-42e631c60a5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 408,  579,    2,  ...,  482,   15,  205],\n",
              "        [ 863,  990, 3734,  ..., 5729,  561,  621],\n",
              "        [5240,  130, 5840,  ..., 9687, 6869, 7832]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKI1VduKcwf"
      },
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = torch.randperm(edges.shape[1])[:batch_size]\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Model Architecture"
      ],
      "metadata": {
        "id": "c6uMVxdDqUAT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"\n",
        "    LightGCN Model, see reference: https://arxiv.org/abs/2002.02126\n",
        "    We omit a dedicated class for LightGCNConvs for easy access to embeddings\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users: int, num_items: int, hidden_dim: int, num_layers: int):\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.users_emb = nn.Embedding(self.num_users, self.hidden_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(self.num_items, self.hidden_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"\n",
        "        Forward pass of the LightGCN model. Returns the init and final\n",
        "        embeddings of the user and item\n",
        "        \"\"\"\n",
        "        edge_index_norm = gcn_norm(edge_index, False)\n",
        "\n",
        "        # The first layer, concat embeddings\n",
        "        x0 = torch.cat([self.users_emb.weight, self.items_emb.weight])\n",
        "        xs = [x0]\n",
        "        xi = x0\n",
        "\n",
        "        # pass x to the next layer\n",
        "        for i in range(self.num_layers):\n",
        "            xi = self.propagate(edge_index_norm, x=xi)\n",
        "            xs.append(xi)\n",
        "\n",
        "        xs = torch.stack(xs, dim=1)\n",
        "        x_final = torch.mean(xs, dim=1)\n",
        "\n",
        "        users_emb, items_emb = \\\n",
        "        torch.split(x_final, [self.num_users, self.num_items])\n",
        "\n",
        "        return users_emb, self.users_emb.weight, items_emb, self.items_emb.weight\n",
        "\n",
        "    def message(self, x: Tensor) -> Tensor:\n",
        "        return x\n",
        "\n",
        "    def propagate(self, edge_index: SparseTensor, x: Tensor) -> Tensor:\n",
        "        x = self.message_and_aggregate(edge_index, x)\n",
        "        return x\n",
        "\n",
        "    def message_and_aggregate(self, edge_index: SparseTensor, x: Tensor) -> Tensor:\n",
        "        return matmul(edge_index, x)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "source": [
        "def bpr_loss(users_emb, user_emb_0, pos_emb, pos_emb_0, neg_emb, neg_emb_0, lambda_val):\n",
        "  # calculate the Bayesian Personalized Ranking from the embeddings \n",
        "    pos_scores = torch.sum(users_emb * pos_emb, dim=1) \n",
        "    neg_scores = torch.sum(users_emb * neg_emb, dim=1)\n",
        "    losses = -torch.log(torch.sigmoid(pos_scores - neg_scores))\n",
        "    loss = torch.mean(losses) + lambda_val * \\\n",
        "    (torch.norm(users_emb_0) + torch.norm(pos_emb_0) + torch.norm(neg_emb_0))\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Evaluation Metrics"
      ],
      "metadata": {
        "id": "X-BrXDrgqt18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The evaluation metric we will use is **Recall@K**, it is defined as the proportion of relevant items that are recommended to a user among the top-K items recommended by the algorithm. \\\\\n",
        "For each user $u$, \\\\\n",
        "Let $P_{u}$ be a set of positive items the user will interact in the future. \\\\\n",
        "Let $R_{u}$ be a set of items recommended by the model, in top-K recommendation, $|R_{u}| = K$. Items that users has already interacted are excluded.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1Ea3_y0eLNNKZT2p13Sa-umZccVuNtRvo)\n",
        "\n",
        "**Recall@K** for user $u$ is $|P_{u}\\cap R_{u}| / |P_{u}|$. \\\\\n",
        "The final Recall@K is computed by averaging the recall values across all users.\n"
      ],
      "metadata": {
        "id": "Z5hSZPcgWe7-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "source": [
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"\n",
        "    Return positive items for all users in form of list\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "source": [
        "def recallAtK(actual_r, pred_r, k):\n",
        "    \"\"\"\n",
        "    Return recall at k and precision at k\n",
        "    \"\"\"\n",
        "    correct_count = torch.sum(pred_r, dim=-1)\n",
        "    # number of items liked by each user in the test set\n",
        "    liked_count = torch.Tensor([len(actual_r[i]) for i in range(len(actual_r))])\n",
        "    \n",
        "    recall = torch.mean(correct_count / liked_count)\n",
        "    precision = torch.mean(correct_count) / k\n",
        "    \n",
        "    return recall.item(), precision.item()\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(model, edge_index, masked_indices, k):\n",
        "\n",
        "    users_emb = model.users_emb.weight\n",
        "    items_emb = model.items_emb.weight\n",
        "\n",
        "    # set ratings matrix between every user and item \n",
        "    rating = torch.matmul(users_emb, items_emb.T)\n",
        "\n",
        "    for index in masked_indices:\n",
        "        user_pos_items = get_user_positive_items(index)\n",
        "        masked_users = []\n",
        "        masked_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            masked_users.extend([user] * len(items))\n",
        "            masked_items.extend(items)\n",
        "\n",
        "        rating[masked_users, masked_items] = float(\"-inf\")\n",
        "\n",
        "    # top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users and ratings for eval\n",
        "    users = edge_index[0].unique()\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    actual_r = [test_user_pos_items[user.item()] for user in users]\n",
        "    pred_r = []\n",
        "\n",
        "    for user in users:\n",
        "        items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in items, top_K_items[user]))\n",
        "        pred_r.append(label)\n",
        "    \n",
        "    pred_r = torch.Tensor(np.array(pred_r).astype('float'))\n",
        "    \n",
        "    return recallAtK(actual_r, pred_r, k)\n",
        "   "
      ],
      "metadata": {
        "id": "-bR5w_TRGlVp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model, edge_index, sparse_edge_index, mask, k, lambda_val):\n",
        "    \"\"\"\n",
        "    Evaluates model loss and metrics including recall, precision\n",
        "    @args: \n",
        "        model: lightgcn model\n",
        "        edge_index: edges for split to evaluate\n",
        "        sparse_edge_index: sparse adjacency matrix \n",
        "        mask: edges for split to remove from eval, in form of list\n",
        "        k: top k item\n",
        "    @return\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb, users_emb_0, items_emb, items_emb_0 = model.forward(sparse_edge_index)\n",
        "    edges = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
        "    \n",
        "    user_indices, pos_indices, neg_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb, users_emb_0 = users_emb[user_indices], users_emb_0[user_indices]\n",
        "    pos_emb, pos_emb_0 = items_emb[pos_indices], items_emb_0[pos_indices]\n",
        "    neg_emb, neg_emb_0 = items_emb[neg_indices], items_emb_0[neg_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb, users_emb_0, pos_emb, pos_emb_0,\n",
        "                    neg_emb, neg_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision = get_metrics(model, edge_index, mask, k)\n",
        "\n",
        "    return loss, recall, precision"
      ],
      "metadata": {
        "id": "_Sr8_Iq1BIUf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "## 5.Training Process\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "source": [
        "# model configurations\n",
        "config = {\n",
        "    'batch_size': 32,\n",
        "    'num_epoch': 50,\n",
        "    'epoch_size': 200,\n",
        "    'lr': 1e-3,\n",
        "    'lr_decay': 0.9,\n",
        "    'topK': 10,\n",
        "    'lambda': 1e-6,\n",
        "    'hidden_dim': 16,\n",
        "    'num_layer': 3,\n",
        "}"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49JDkBtKTfE-"
      },
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = LightGCN(num_users, num_movies, config['hidden_dim'], config['num_layer'])\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=config['lr_decay'])\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "5f79a42f-2295-4f22-d040-8d498576d69f"
      },
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(config['num_epoch']):\n",
        "  for iter in range(config['epoch_size']):\n",
        "    # forward propagation\n",
        "    users_emb, users_emb_0, items_emb, items_emb_0 = \\\n",
        "        model.forward(train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_indices, neg_indices = \\\n",
        "        sample_mini_batch(config['batch_size'], train_edge_index)\n",
        "    \n",
        "    user_indices = user_indices.to(device)\n",
        "    pos_indices = pos_indices.to(device)\n",
        "    neg_indices = neg_indices.to(device)\n",
        "    \n",
        "    users_emb, users_emb_0 = users_emb[user_indices], users_emb_0[user_indices]\n",
        "    pos_emb, pos_emb_0 = items_emb[pos_indices], items_emb_0[pos_indices]\n",
        "    neg_emb, neg_emb_0 = items_emb[neg_indices], items_emb_0[neg_indices]\n",
        "\n",
        "    # loss computation\n",
        "    loss = bpr_loss(users_emb, users_emb_0, \n",
        "                    pos_emb, pos_emb_0,\n",
        "                    neg_emb, neg_emb_0,\n",
        "                    config['lambda'])\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  val_loss, recall, precision = evaluation(model, val_edge_index, \n",
        "                                           val_sparse_edge_index, \n",
        "                                           [train_edge_index], \n",
        "                                           config['topK'],\n",
        "                                           config['lambda'])\n",
        "  \n",
        "\n",
        "  print('Epoch {:d}: train_loss: {:.4f}, val_loss: {:.4f}, recall: {:.4f}, precision: {:.4f}'\\\n",
        "        .format(epoch, loss, val_loss, recall, precision))\n",
        "  train_losses.append(loss.item())\n",
        "  val_losses.append(val_loss)\n",
        "\n",
        "  scheduler.step()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8f6eeb0eee42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0miter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# forward propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLcdvV5iXBSv"
      },
      "source": [
        "iters = [config['epoch_size'] * epoch for epoch in range(config['num_epoch'])]\n",
        "plt.plot(iters, train_losses, label='Train')\n",
        "plt.plot(iters, val_losses, label='Validation')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Losses')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UjCTMQ_N5e"
      },
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision \\\n",
        "    = evaluation(model, \n",
        "                test_edge_index, \n",
        "                test_sparse_edge_index, \n",
        "                [train_edge_index, val_edge_index],\n",
        "                config['topK'],\n",
        "                config['lambda'])\n",
        "    \n",
        "\n",
        "print('Test set: train_loss: {:.4f}, val_loss: {:.4f}, recall: {:.4f}, precision: {:.4f}'\\\n",
        "        .format(test_loss, test_recall, test_precision))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "# Make New Recommendatios for a Given User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzuMPxFVZlQn"
      },
      "source": [
        "model.eval()\n",
        "df = pd.read_csv(movie_path)\n",
        "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "user_pos_items = get_user_positive_items(edge_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(user_id, num_recs):\n",
        "    user = user_mapping[user_id]\n",
        "    e_u = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ e_u\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some suggested movies for user {user_id}\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
      ],
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSFgwnaecWBw"
      },
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLkRpNldrSQe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}