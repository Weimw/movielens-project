{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Weimw/movielens-project/blob/main/CS224w_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Packages and Libraries"
      ],
      "metadata": {
        "id": "aO6HhJV4NsX6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxoenua1-u5r"
      },
      "source": [
        "# Install required packages.\n",
        "%%capture\n",
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing"
      ],
      "metadata": {
        "id": "sXnpUp2yNqzH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRC_IazQ4Oj",
        "outputId": "93d5acb6-89cc-4dc9-9893-70be633856c9"
      },
      "source": [
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` data connects users (as given by `userId`) and movies (as given by `movieId`). We first want to create a mapping that maps entry IDs to a consecutive value in the range `{ 0, ..., num_rows - 1 }`. This is very helpful because it will make the adjency matrix as compact as possible. We then create an `edge_index` which is of shape `[2, num_ratings]` from `ratings.csv`. The first row represents the mapped `userId` and the second row represents the mapped `movieId`. A specific column represents a connection (i.e rating) between a user and a movie. The `edge_index` tensor is very important when propagating the messages along the graph network. "
      ],
      "metadata": {
        "id": "S0bzq0x6QC3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(movie_path: str, rating_path: str): \n",
        "  '''\n",
        "    Args:\n",
        "         movie_path (str): A string representing the file path to the movies dataset.\n",
        "         rating_path (str): A string representing the file path to the ratings dataset.\n",
        "    \n",
        "    Returns:\n",
        "         edge_index (torch.Tensor): the indices of edges in the adjacency matrix for the ratings dataset.\n",
        "         num_users (int): number of unique users in the ratings dataset.\n",
        "         num_movies (int): number of unique movies in the ratings dataset.\n",
        "  '''\n",
        "  # load movies and ratings dataset\n",
        "  movie_df = pd.read_csv(movie_path, index_col = 'movieId')\n",
        "  rating_df = pd.read_csv(rating_path, index_col = 'userId') \n",
        "\n",
        "  # create mapping to continous range\n",
        "  movie_mapping = {idx: i for i, idx in enumerate(movie_df.index.unique())}\n",
        "  user_mapping = {idx: i for i, idx in enumerate(rating_df.index.unique())}\n",
        "  num_users, num_movies = len(rating_df.index.unique()), len(movie_df.index.unique())\n",
        "\n",
        "  rating_df = pd.read_csv(rating_path)\n",
        "  edge_index = None\n",
        "  users = [user_mapping[idx] for idx in rating_df['userId']]\n",
        "  movies = [movie_mapping[idx] for idx in rating_df['movieId']]\n",
        "\n",
        "  # filter for edges with a high rating\n",
        "  ratings = rating_df['rating'].values\n",
        "  recommend_bool = torch.from_numpy(ratings).view(-1, 1).to(torch.long) >= 4\n",
        "\n",
        "  edge_index = [[],[]]\n",
        "  for i in range(recommend_bool.shape[0]):\n",
        "    if recommend_bool[i]:\n",
        "      edge_index[0].append(users[i])\n",
        "      edge_index[1].append(movies[i])\n",
        "    \n",
        "  edge_index = torch.tensor(edge_index)\n",
        "  return edge_index, num_users, num_movies"
      ],
      "metadata": {
        "id": "mLEBcsyv5abc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index, num_users, num_movies = preprocessing(movie_path, rating_path)"
      ],
      "metadata": {
        "id": "lm-VDQZA_GAP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then split the whole dataset into train/val/test sets. The split is conducted on edge level. To be more specifc, we will split the whole dataset into 80/10/10 by random, so that each set will have a subset of `edge_index`."
      ],
      "metadata": {
        "id": "HVRWWdhbRqhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_ratings = edge_index.shape[1]\n",
        "rating_indices = np.arange(num_ratings)\n",
        "\n",
        "indices_train, indices_val_test = train_test_split(rating_indices, test_size = 0.2, random_state = 42)\n",
        "indices_val, indices_test = train_test_split(indices_val_test, test_size = 0.5, random_state = 42)\n",
        "\n",
        "# slice the whole dataset by split indices, then convert to SparseTensor for later training\n",
        "def generate_edge(edge_indices: np.ndarray):\n",
        "  '''\n",
        "  Args:\n",
        "      edge_indices (np.ndarray): An array representing the indices of edges in the dataset.\n",
        "\n",
        "  Returns:\n",
        "      sub_edge_index (torch.Tensor): indices of edges in the specified subset.\n",
        "      edge_index_sparse (SparseTensor): A sparse tensor representing the adjacency matrix for the subset of edges.\n",
        "  '''\n",
        "  sub_edge_index = edge_index[:, edge_indices]\n",
        "  num_nodes = num_users + num_movies\n",
        "  edge_index_sparse = SparseTensor(row = sub_edge_index[0],\n",
        "                                   col = sub_edge_index[1],\n",
        "                                   sparse_sizes = (num_nodes, num_nodes))\n",
        "  return sub_edge_index, edge_index_sparse\n",
        "\n",
        "train_edge_index, train_sparse_edge_index = generate_edge(indices_train)\n",
        "val_edge_index, val_sparse_edge_index = generate_edge(indices_val)\n",
        "test_edge_index, test_sparse_edge_index = generate_edge(indices_test)"
      ],
      "metadata": {
        "id": "d9op9aVbTFIf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In training process, we will use mini-batch strategy and sample several positive edges and negative edges within each batch. A positive edge is defined as observed/training user-item interactions. During training, we want to penalize those negative edges by assigning larger loss to them. We will utilize the `structured_negative_sampling` function in PyG, which samples a negative edge for every positive edge in the graph, given by `edge_index`."
      ],
      "metadata": {
        "id": "tvZpaxT_aFCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "structured_negative_sampling samples a negative edge :obj:`(i,k)` for every positive edge :obj:`(i,j)` in the \n",
        "graph given by :attr:`edge_index`, and returns it as a tuple of the form :obj:`(i,j,k)`.\n",
        "'''\n",
        "edges = structured_negative_sampling(train_edge_index)\n",
        "edges = torch.stack(edges, dim=0)\n",
        "edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uxt8LxCnkE7",
        "outputId": "260e062a-4d04-4cdf-acad-cb5fbae83edd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 408,  579,    2,  ...,  482,   15,  205],\n",
              "        [ 863,  990, 3734,  ..., 5729,  561,  621],\n",
              "        [4043, 3691, 5021,  ...,  184, 6937, 8849]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKI1VduKcwf"
      },
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = torch.randperm(edges.shape[1])[:batch_size]\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Model Architecture"
      ],
      "metadata": {
        "id": "c6uMVxdDqUAT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, hidden_dim, num_layers):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.users_emb = nn.Embedding(self.num_users, self.hidden_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(self.num_items, self.hidden_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\" Forward propagation of LightGCN Model. We omit the dedicated Convs \n",
        "        layer for easy access to the initial and final embeddings in the model\n",
        "        for BPR calculation\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        edge_index_norm = gcn_norm(edge_index, False)\n",
        "\n",
        "        xs = []\n",
        "        # The first layer, concat embeddings\n",
        "        x0 = torch.cat([self.users_emb.weight, self.items_emb.weight])\n",
        "        xs.append(x0)\n",
        "        xi = x0\n",
        "\n",
        "        # pass x to the next layer\n",
        "        for i in range(self.num_layers):\n",
        "            xi = self.propagate(edge_index_norm, x=xi)\n",
        "            xs.append(xi)\n",
        "\n",
        "        xs = torch.stack(xs, dim=1)\n",
        "        x_final = torch.mean(xs, dim=1)\n",
        "\n",
        "        users_emb, items_emb = \\\n",
        "        torch.split(x_final, [self.num_users, self.num_items])\n",
        "\n",
        "        return users_emb, self.users_emb.weight, items_emb, self.items_emb.weight\n",
        "\n",
        "    def message(self, x: Tensor) -> Tensor:\n",
        "        return x\n",
        "\n",
        "    def message_and_aggregate(self, edge_index: SparseTensor, x: Tensor) -> Tensor:\n",
        "        return matmul(edge_index, x)\n",
        "\n",
        "model = LightGCN(num_users, num_movies, 64, 3)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "source": [
        "def bpr_loss(users_emb, user_emb_0, pos_emb, pos_emb_0, neg_emb, neg_emb_0, num_users):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = (1/2) * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_emb_0.norm(2).pow(2) +\n",
        "                             neg_emb_0.norm(2).pow(2)) / num_users\n",
        "\n",
        "    pos_scores = torch.mul(users_emb, pos_emb)\n",
        "    pos_scores = torch.sum(pos_scores, dim=1)\n",
        "    neg_scores = torch.mul(users_emb, neg_emb)\n",
        "    neg_scores = torch.sum(neg_scores, dim=1)\n",
        "\n",
        "    bpr_loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores))\n",
        "\n",
        "    return bpr_loss, reg_loss"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Evaluation Metrics"
      ],
      "metadata": {
        "id": "X-BrXDrgqt18"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7HVr3qLQGx"
      },
      "source": [
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "source": [
        "# helper function to get N_u\n",
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6_741LlTMwI"
      },
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr_qESXASsVw"
      },
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        sparse_edge_index)\n",
        "    edges = structured_negative_sampling(\n",
        "        edge_index, contains_neg_self_loops=False)\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
        "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(\n",
        "        model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "## 5.Training Process\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "source": [
        "# model configurations\n",
        "config = {\n",
        "    'batch_size': 32,\n",
        "    'num_epoch': 50,\n",
        "    'epoch_size': 200,\n",
        "    'lr': 1e-3,\n",
        "    'lr_decay': 0.95\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49JDkBtKTfE-"
      },
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=config['lr_decay'])\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "278b98f5-8882-4b99-fc17-6a75ad59982d"
      },
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(config['num_epoch']):\n",
        "  for iter in range(config['epoch_size']):\n",
        "    # forward propagation\n",
        "    users_emb, users_emb_0, items_emb, items_emb_0 = \\\n",
        "        model.forward(train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_indices, neg_indices = \\\n",
        "        sample_mini_batch(config['batch_size'], train_edge_index)\n",
        "    \n",
        "    user_indices = user_indices.to(device)\n",
        "    pos_indices = pos_indices.to(device)\n",
        "    neg_indices = neg_indices.to(device)\n",
        "    \n",
        "    users_emb, users_emb_0 = users_emb[user_indices], users_emb_0[user_indices]\n",
        "    pos_emb, pos_emb_0 = items_emb[pos_indices], items_emb_0[pos_indices]\n",
        "    neg_emb, neg_emb_0 = items_emb[neg_indices], items_emb_0[neg_indices]\n",
        "\n",
        "    # loss computation\n",
        "    train_loss, reg_loss = bpr_loss(users_emb, users_emb_0, \n",
        "                                    pos_emb, pos_emb_0,\n",
        "                                    neg_emb, neg_emb_0,\n",
        "                                    len(user_indices))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  val_loss, recall, precision, ndcg = evaluation(\n",
        "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
        "  print(f\"[Epoch {epoch}: train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "  train_losses.append(train_loss.item())\n",
        "  val_losses.append(val_loss)\n",
        "  model.train()\n",
        "\n",
        "  scheduler.step()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-01555361b716>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   val_loss, recall, precision, ndcg = evaluation(\n\u001b[0;32m---> 35\u001b[0;31m             model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n\u001b[0m\u001b[1;32m     36\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Epoch {epoch}: train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'K' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "nLcdvV5iXBSv",
        "outputId": "ed0ff0cf-3009-442c-b44f-4ef78616741f"
      },
      "source": [
        "iters = [config['epoch_size'] * epoch for epoch in range(len(config['num_epoch']))]\n",
        "plt.plot(iters, train_losses, label='Train')\n",
        "plt.plot(iters, val_losses, label='Validation')\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Losses')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UjCTMQ_N5e"
      },
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "# Make New Recommendatios for a Given User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzuMPxFVZlQn"
      },
      "source": [
        "model.eval()\n",
        "df = pd.read_csv(movie_path)\n",
        "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "user_pos_items = get_user_positive_items(edge_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(user_id, num_recs):\n",
        "    user = user_mapping[user_id]\n",
        "    e_u = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ e_u\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some suggested movies for user {user_id}\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
      ],
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSFgwnaecWBw"
      },
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLkRpNldrSQe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}