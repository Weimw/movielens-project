{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Weimw/movielens-project/blob/main/CS224w_Link_Prediction_on_MovieLens(ver1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh7LaSzfwcj2",
        "outputId": "7743b891-5152-4766-b8e6-121e7c527ecf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.1+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AsWUrVh7vZtM"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "%%capture\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "metadata": {
        "id": "yD3DnQe9RL9h"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Link Prediction on MovieLens\n",
        "\n",
        "This colab notebook shows how to load a set of `*.csv` files as input and construct a heterogeneous graph from it.\n",
        "We will then use this dataset as input into a [heterogeneous graph model](https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html#hgtutorial), and use it for the task of link prediction.\n",
        "A few code cells require user input to let the code run through successfully.\n",
        "Parts of this tutorial are also available in [our documentation](https://pytorch-geometric.readthedocs.io/en/latest/notes/load_csv.html).\n",
        "\n",
        "We are going to use the [MovieLens dataset](https://grouplens.org/datasets/movielens/) collected by the GroupLens research group.\n",
        "This toy dataset describes ratings and tagging activity from MovieLens.\n",
        "The dataset contains approximately 100k ratings across more than 9k movies from more than 600 users.\n",
        "We are going to use this dataset to generate two node types holding data for movies and users, respectively, and one edge type connecting users and movies, representing the relation of whether a user has rated a specific movie.\n",
        "\n",
        "The link prediction task then tries to predict missing ratings, and can, for example, be used to recommend users new movies."
      ],
      "metadata": {
        "id": "vit8xKCiXAue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneous Graph Creation\n",
        "\n",
        "First, we download the dataset to an arbitrary folder (in this case, the current directory):"
      ],
      "metadata": {
        "id": "N_pshZh8Y3dw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import download_url, extract_zip\n",
        "\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movies_path = './ml-latest-small/movies.csv'\n",
        "ratings_path = './ml-latest-small/ratings.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciYr7NWEv5_o",
        "outputId": "8155e727-7d76-4fd5-aa89-3fb4c162a2e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we create the heterogeneous graph, letâ€™s take a look at the data."
      ],
      "metadata": {
        "id": "B89RD_evY7uu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "print('movies.csv:')\n",
        "print('===========')\n",
        "print(pd.read_csv(movies_path)[[\"movieId\", \"genres\"]].head())\n",
        "print()\n",
        "print('ratings.csv:')\n",
        "print('============')\n",
        "print(pd.read_csv(ratings_path)[[\"userId\", \"movieId\"]].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6ixkcCOwCDi",
        "outputId": "fc7be953-91e2-4d09-b765-b0fa09de7f67"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "movies.csv:\n",
            "===========\n",
            "   movieId                                       genres\n",
            "0        1  Adventure|Animation|Children|Comedy|Fantasy\n",
            "1        2                   Adventure|Children|Fantasy\n",
            "2        3                               Comedy|Romance\n",
            "3        4                         Comedy|Drama|Romance\n",
            "4        5                                       Comedy\n",
            "\n",
            "ratings.csv:\n",
            "============\n",
            "   userId  movieId\n",
            "0       1        1\n",
            "1       1        3\n",
            "2       1        6\n",
            "3       1       47\n",
            "4       1       50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the `movies.csv` file provides two useful columns: `movieId` assigns a unique identifier to each movie, while the `genres` column represent genres of the given movie.\n",
        "We can make use of this column to define a feature representation that can be easily interpreted by machine learning models."
      ],
      "metadata": {
        "id": "LgXipuWTZK39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire movie data frame into memory:\n",
        "movies_df = pd.read_csv(movies_path, index_col='movieId')\n",
        "\n",
        "# Split genres and convert into indicator variables:\n",
        "genres = movies_df['genres'].str.get_dummies('|')\n",
        "print(genres[[\"Action\", \"Adventure\", \"Drama\", \"Horror\"]].head())\n",
        "\n",
        "# Use genres as movie input features:\n",
        "movie_feat = torch.from_numpy(genres.values).to(torch.float)\n",
        "assert movie_feat.size() == (9742, 20)  # 20 genres in total."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd_BJMNcwJ7k",
        "outputId": "b3a9affb-abd5-407b-d8a7-6aa6c72c419e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Action  Adventure  Drama  Horror\n",
            "movieId                                  \n",
            "1             0          1      0       0\n",
            "2             0          1      0       0\n",
            "3             0          0      0       0\n",
            "4             0          0      1       0\n",
            "5             0          0      0       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "movie_feat = movie_feat.to(device)"
      ],
      "metadata": {
        "id": "_3kOFOt_TA0K"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_feat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KfpXjQfQZWf",
        "outputId": "3177a731-ec8b-48e5-8fe6-71ea443688e2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9742, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` data connects users (as given by `userId`) and movies (as given by `movieId`).\n",
        "Due to simplicity, we do not make use of the additional `timestamp` and `rating` information.\n",
        "Here, we first read the `*.csv` file from disk, and create a mapping that maps entry IDs to a consecutive value in the range `{ 0, ..., num_rows - 1 }`.\n",
        "This is needed as we want our final data representation to be as compact as possible, *e.g.*, the representation of a movie in the first row should be accessible via `x[0]`.\n",
        "\n",
        "Afterwards, we obtain the final `edge_index` representation of shape `[2, num_ratings]` from `ratings.csv` by merging mapped user and movie indices with the raw indices given by the original data frame."
      ],
      "metadata": {
        "id": "KLaDBVP4plsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire ratings data frame into memory:\n",
        "ratings_df = pd.read_csv(ratings_path)\n",
        "ratings_df = ratings_df[ratings_df['rating'] >= 3]\n",
        "\n",
        "# Create a mapping from unique user indices to range [0, num_user_nodes):\n",
        "unique_user_id = ratings_df['userId'].unique()\n",
        "unique_user_id = pd.DataFrame(data={\n",
        "    'userId': unique_user_id,\n",
        "    'mappedID': pd.RangeIndex(len(unique_user_id)),\n",
        "})\n",
        "print(\"Mapping of user IDs to consecutive values:\")\n",
        "print(\"==========================================\")\n",
        "print(unique_user_id.head())\n",
        "print()\n",
        "# Create a mapping from unique movie indices to range [0, num_movie_nodes):\n",
        "unique_movie_id = pd.DataFrame(data={\n",
        "    'movieId': movies_df.index,\n",
        "    'mappedID': pd.RangeIndex(len(movies_df)),\n",
        "})\n",
        "print(\"Mapping of movie IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_movie_id.head())\n",
        "\n",
        "# Perform merge to obtain the edges from users and movies:\n",
        "ratings_user_id = pd.merge(ratings_df['userId'], unique_user_id,\n",
        "                            left_on='userId', right_on='userId', how='left')\n",
        "ratings_user_id = torch.from_numpy(ratings_user_id['mappedID'].values)\n",
        "ratings_movie_id = pd.merge(ratings_df['movieId'], unique_movie_id,\n",
        "                            left_on='movieId', right_on='movieId', how='left')\n",
        "ratings_movie_id = torch.from_numpy(ratings_movie_id['mappedID'].values)\n",
        "\n",
        "# With this, we are ready to construct our `edge_index` in COO format\n",
        "# following PyG semantics:\n",
        "edge_index = torch.stack([ratings_user_id, ratings_movie_id], dim=0)\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"Final edge indices pointing from users to movies:\")\n",
        "print(\"=================================================\")\n",
        "print(edge_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMGYv83WzSRr",
        "outputId": "1048ecfa-57bf-499d-8345-612a1bb4151c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of user IDs to consecutive values:\n",
            "==========================================\n",
            "   userId  mappedID\n",
            "0       1         0\n",
            "1       2         1\n",
            "2       3         2\n",
            "3       4         3\n",
            "4       5         4\n",
            "\n",
            "Mapping of movie IDs to consecutive values:\n",
            "===========================================\n",
            "   movieId  mappedID\n",
            "0        1         0\n",
            "1        2         1\n",
            "2        3         2\n",
            "3        4         3\n",
            "4        5         4\n",
            "\n",
            "Final edge indices pointing from users to movies:\n",
            "=================================================\n",
            "tensor([[   0,    0,    0,  ...,  608,  608,  608],\n",
            "        [   0,    2,    5,  ..., 9462, 9463, 9503]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(unique_user_id)\n",
        "num_movies = len(unique_movie_id)"
      ],
      "metadata": {
        "id": "iwL7gIuiD0Ax"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-test split"
      ],
      "metadata": {
        "id": "d3sGdDylQsDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices, test_size=0.2, random_state=42)\n",
        "val_indices, test_indices = train_test_split(\n",
        "    test_indices, test_size=0.5, random_state=42)\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ],
      "metadata": {
        "id": "HEwf6HYEQq4F"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "train_sparse_edge_index = SparseTensor(row=train_edge_index[0], col=train_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "val_sparse_edge_index = SparseTensor(row=val_edge_index[0], col=val_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))\n",
        "test_sparse_edge_index = SparseTensor(row=test_edge_index[0], col=test_edge_index[1], sparse_sizes=(\n",
        "    num_users + num_movies, num_users + num_movies))"
      ],
      "metadata": {
        "id": "O_wpN0ImQqoM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = random.choices(\n",
        "        [i for i in range(edges[0].shape[0])], k=batch_size)\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "metadata": {
        "id": "s5Cz1NkrQqel"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Samples a negative edge :obj:`(i,k)` for every positive edge :obj:`(i,j)` in the \n",
        "graph given by :attr:`edge_index`, and returns it as a tuple of the form :obj:`(i,j,k)`.\n",
        "'''\n",
        "edges = structured_negative_sampling(train_edge_index)\n",
        "edges = torch.stack(edges, dim=0)\n",
        "edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qECuzLIyRmNu",
        "outputId": "51dada81-426e-48d9-8692-27e3c82c8ad0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 437,  446,  451,  ...,  597,    6,  121],\n",
              "        [5161,  508, 3640,  ..., 6573, 5687, 3216],\n",
              "        [ 155, 9374, 5577,  ...,  476, 7368, 3020]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGCN layer"
      ],
      "metadata": {
        "id": "hSLFT70cMsKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "\n",
        "\n",
        "class LightGCN(MessagePassing):\n",
        "  def __init__(self, num_users, num_movies, hidden_channels, movie_feat, num_layers = 3, add_self_loops = False):\n",
        "    super().__init__()\n",
        "    self.num_users = num_users\n",
        "    self.num_movies = num_movies\n",
        "    self.hidden_channels = hidden_channels\n",
        "    self.num_layers = num_layers\n",
        "    self.add_self_loops = add_self_loops\n",
        "    self.movie_feat = movie_feat\n",
        "    self.movie_feat = self.movie_feat.to(device)\n",
        "\n",
        "    self.movie_lin = nn.Linear(20, self.hidden_channels)\n",
        "    self.users_emb = nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.hidden_channels) # e_u^0\n",
        "    self.items_emb = nn.Embedding(num_embeddings=self.num_movies, embedding_dim=self.hidden_channels) # e_i^0\n",
        "\n",
        "    nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "    nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    self.users_emb = self.users_emb.to(device)\n",
        "    self.items_emb = self.items_emb.to(device)\n",
        "\n",
        "  def forward(self, edge_index):\n",
        "    edge_index_norm = gcn_norm(edge_index, add_self_loops = self.add_self_loops)\n",
        "\n",
        "    #print(self.users_emb.weight.get_device())\n",
        "\n",
        "    print(self.movie_lin(self.movie_feat).get_device())\n",
        "    \n",
        "    emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight + self.movie_lin(self.movie_feat)]) # E^0\n",
        "    embs = [emb_0]\n",
        "    emb_k = emb_0\n",
        "\n",
        "    # multi-scale diffusion\n",
        "    for i in range(self.num_layers):\n",
        "      emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "      embs.append(emb_k)\n",
        "\n",
        "    embs = torch.stack(embs, dim=1)\n",
        "    emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "    users_emb_final, items_emb_final = torch.split(emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "    # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "    return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight + self.movie_lin(movie_feat)\n",
        "\n",
        "  def message(self, x_j: Tensor) -> Tensor:\n",
        "    return x_j\n",
        "  \n",
        "  def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "    # computes \\tilde{A} @ x\n",
        "    return matmul(adj_t, x)\n",
        "\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(self, x_user: Tensor, x_movie: Tensor, edge_label_index: Tensor) -> Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
        "\n",
        "        # Apply dot-product to get a prediction per supervision edge:\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # Since the dataset does not come with rich features, we also learn two\n",
        "        # embedding matrices for users and movies:\n",
        "        '''\n",
        "        self.movie_lin = torch.nn.Linear(20, hidden_channels)\n",
        "        self.user_emb = torch.nn.Embedding(num_users, hidden_channels)\n",
        "        self.movie_emb = torch.nn.Embedding(num_movies, hidden_channels)\n",
        "        '''\n",
        "\n",
        "        self.gcn = LightGCN(num_users, num_movies, hidden_channels, movie_feat)\n",
        "\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, edge_index) -> Tensor:\n",
        "        # `x_dict` holds feature matrices of all node types\n",
        "        # `edge_index_dict` holds all edge indices of all edge types\n",
        "\n",
        "        users_emb_final, users_emb_0, items_emb_final, items_emb_0 = self.gcn.forward(edge_index)\n",
        "\n",
        "        pred = self.classifier(\n",
        "            users_emb_final,\n",
        "            items_emb_final,\n",
        "            edge_index,\n",
        "        )\n",
        "\n",
        "        return pred\n",
        "\n",
        "        \n",
        "model = Model(hidden_channels=64)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e1d826-7211-407d-fd78-7e037c4a4180",
        "id": "Z3ReVHYv8WKj"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (gcn): LightGCN()\n",
            "  (classifier): Classifier()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        users_emb_0 (torch.Tensor): e_u_0\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        pos_items_emb_0 (torch.Tensor): positive e_i_0\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        neg_items_emb_0 (torch.Tensor): negative e_i_0\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    reg_loss = lambda_val * (users_emb_0.norm(2).pow(2) +\n",
        "                             pos_items_emb_0.norm(2).pow(2) +\n",
        "                             neg_items_emb_0.norm(2).pow(2)) # L2 loss\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1) # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1) # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores)) + reg_loss\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "xkPryhjiVmeO"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "B1JWB1ePWBeV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "LAMBDA = 1E-6\n",
        "ITERATION = 10\n",
        "BATCH_SIZE = 1024\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iter in range(ITERATION):\n",
        "    # forward propagation\n",
        "    total_loss = total_examples = 0\n",
        "\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        BATCH_SIZE, train_edge_index)\n",
        "    user_indices, pos_item_indices, neg_item_indices, movie_feat = user_indices.to(\n",
        "        device), pos_item_indices.to(device), neg_item_indices.to(device), movie_feat.to(device)\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
        "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    total_loss += float(train_loss) * BATCH_SIZE\n",
        "    total_examples += BATCH_SIZE\n",
        "\n",
        "print(f\"Epoch: {iter:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "id": "ykZ4263UUQdi",
        "outputId": "af462961-71ea-4768-ff36-c9271f427c4f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-32807092f5f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n\u001b[0m\u001b[1;32m     13\u001b[0m         train_sparse_edge_index)\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-91-6c98dd5cb3ff>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, edge_index)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# `edge_index_dict` holds all edge indices of all edge types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0musers_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musers_emb_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_emb_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems_emb_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         pred = self.classifier(\n",
            "\u001b[0;32m<ipython-input-91-6c98dd5cb3ff>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, edge_index)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#print(self.users_emb.weight.get_device())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0memb_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmovie_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# E^0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Heterogeneous Link-level GNN\n",
        "\n",
        "Training our GNN is then similar to training any PyTorch model.\n",
        "We move the model to the desired device, and initialize an optimizer that takes care of adjusting model parameters via stochastic gradient descent.\n",
        "\n",
        "The training loop then iterates over our mini-batches, applies the forward computation of the model, computes the loss from ground-truth labels and obtained predictions (here we make use of binary cross entropy), and adjusts model parameters via back-propagation and stochastic gradient descent."
      ],
      "metadata": {
        "id": "05dfew-WuWHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 6):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # TODO: Move `sampled_data` to the respective `device`\n",
        "        # TODO: Run `forward` pass of the model\n",
        "        # TODO: Apply binary cross entropy via\n",
        "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
        "        sampled_data = sampled_data.to(device)\n",
        "        pred = model.forward(sampled_data)\n",
        "        loss = F.binary_cross_entropy_with_logits(pred, sampled_data[\"user\", \"rates\", \"movie\"].edge_label)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqLuXEcrAMru",
        "outputId": "88fbe21c-b25a-4534-c32c-2edac6f5aa96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:00<00:00, 155.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.6931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:00<00:00, 167.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.6928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:00<00:00, 169.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.6908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:00<00:00, 171.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.6823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [00:00<00:00, 161.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Loss: 0.6631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a Heterogeneous Link-level GNN\n",
        "\n",
        "After training, we evaluate our model on useen data coming from the validation set.\n",
        "For this, we define a new `LinkNeighborLoader` (which now iterates over the edges in the validation set), obtain the predictions on validation edges by running the model, and finally evaluate the performance of the model by computing the AUC score over the set of predictions and their corresponding ground-truth edges (including both positive and negative edges)."
      ],
      "metadata": {
        "id": "Yq-I2xaYueF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data[\"user\", \"rates\", \"movie\"].edge_label_index\n",
        "edge_label = val_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,\n",
        "    num_neighbors=[20, 10],\n",
        "    edge_label_index=((\"user\", \"rates\", \"movie\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.min() >= 0\n",
        "assert sampled_data[\"user\", \"rates\", \"movie\"].edge_label.max() <= 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIrRn9YoNllj",
        "outputId": "5b87caee-1953-4b91-ce47-f3b8567b8020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1muser\u001b[0m={\n",
            "    node_id=[608],\n",
            "    n_id=[608]\n",
            "  },\n",
            "  \u001b[1mmovie\u001b[0m={\n",
            "    node_id=[2575],\n",
            "    x=[2575, 20],\n",
            "    n_id=[2575]\n",
            "  },\n",
            "  \u001b[1m(user, rates, movie)\u001b[0m={\n",
            "    edge_index=[2, 18358],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    e_id=[18358],\n",
            "    input_id=[384]\n",
            "  },\n",
            "  \u001b[1m(movie, rev_rates, user)\u001b[0m={\n",
            "    edge_index=[2, 7790],\n",
            "    e_id=[7790]\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        # TODO: Collect predictions and ground-truths and write them into\n",
        "        # `preds` and `ground_truths`.\n",
        "        sampled_data = sampled_data.to(device)\n",
        "        pred = model.forward(sampled_data)\n",
        "        preds.append(pred)\n",
        "        ground_truth = sampled_data[\"user\", \"rates\", \"movie\"].edge_label\n",
        "        ground_truths.append(ground_truth)\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "auc = roc_auc_score(ground_truth, pred)\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "Vi25Z7lFPPjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80653090-711f-4648-fd58-0eff68a316f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 64/64 [00:00<00:00, 215.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.4258\n"
          ]
        }
      ]
    }
  ]
}