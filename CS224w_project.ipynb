{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Weimw/movielens-project/blob/main/CS224w_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install Packages and Libraries"
      ],
      "metadata": {
        "id": "aO6HhJV4NsX6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxoenua1-u5r"
      },
      "source": [
        "# Install required packages.\n",
        "%%capture\n",
        "import torch\n",
        "import os\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from torch import nn, optim, Tensor\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data Preprocessing"
      ],
      "metadata": {
        "id": "sXnpUp2yNqzH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cRC_IazQ4Oj",
        "outputId": "c1d82409-4835-4aa3-9d28-970c8f10a410"
      },
      "source": [
        "# download the dataset\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
        "extract_zip(download_url(url, '.'), '.')\n",
        "\n",
        "movie_path = './ml-latest-small/movies.csv'\n",
        "rating_path = './ml-latest-small/ratings.csv'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
            "Extracting ./ml-latest-small.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` data connects users (as given by `userId`) and movies (as given by `movieId`). We first want to create a mapping that maps entry IDs to a consecutive value in the range `{ 0, ..., num_rows - 1 }`. This is very helpful because it will make the adjency matrix as compact as possible. We then create an `edge_index` which is of shape `[2, num_ratings]` from `ratings.csv`. The first row represents the mapped `userId` and the second row represents the mapped `movieId`. A specific column represents a connection (i.e rating) between a user and a movie. The `edge_index` tensor is very important when propagating the messages along the graph network. "
      ],
      "metadata": {
        "id": "S0bzq0x6QC3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(movie_path: str, rating_path: str): \n",
        "  '''\n",
        "    Args:\n",
        "         movie_path (str): A string representing the file path to the movies dataset.\n",
        "         rating_path (str): A string representing the file path to the ratings dataset.\n",
        "    \n",
        "    Returns:\n",
        "         edge_index (torch.Tensor): the indices of edges in the adjacency matrix for the ratings dataset.\n",
        "         num_users (int): number of unique users in the ratings dataset.\n",
        "         num_movies (int): number of unique movies in the ratings dataset.\n",
        "  '''\n",
        "  # load movies and ratings dataset\n",
        "  movie_df = pd.read_csv(movie_path, index_col = 'movieId')\n",
        "  rating_df = pd.read_csv(rating_path, index_col = 'userId') \n",
        "\n",
        "  # create mapping to continous range\n",
        "  movie_mapping = {idx: i for i, idx in enumerate(movie_df.index.unique())}\n",
        "  user_mapping = {idx: i for i, idx in enumerate(rating_df.index.unique())}\n",
        "  num_users, num_movies = len(rating_df.index.unique()), len(movie_df.index.unique())\n",
        "\n",
        "  rating_df = pd.read_csv(rating_path)\n",
        "  edge_index = None\n",
        "  users = [user_mapping[idx] for idx in rating_df['userId']]\n",
        "  movies = [movie_mapping[idx] for idx in rating_df['movieId']]\n",
        "\n",
        "  # filter for edges with a high rating\n",
        "  ratings = rating_df['rating'].values\n",
        "  recommend_bool = torch.from_numpy(ratings).view(-1, 1).to(torch.long) >= 4\n",
        "\n",
        "  edge_index = [[],[]]\n",
        "  for i in range(recommend_bool.shape[0]):\n",
        "    if recommend_bool[i]:\n",
        "      edge_index[0].append(users[i])\n",
        "      edge_index[1].append(movies[i])\n",
        "    \n",
        "  edge_index = torch.tensor(edge_index)\n",
        "  return edge_index, num_users, num_movies"
      ],
      "metadata": {
        "id": "mLEBcsyv5abc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index, num_users, num_movies = preprocessing(movie_path, rating_path)"
      ],
      "metadata": {
        "id": "lm-VDQZA_GAP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We then split the whole dataset into train/val/test sets. The split is conducted on edge level. To be more specifc, we will split the whole dataset into 80/10/10 by random, so that each set will have a subset of `edge_index`."
      ],
      "metadata": {
        "id": "HVRWWdhbRqhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_ratings = edge_index.shape[1]\n",
        "rating_indices = np.arange(num_ratings)\n",
        "\n",
        "indices_train, indices_val_test = train_test_split(rating_indices, test_size = 0.2, random_state = 42)\n",
        "indices_val, indices_test = train_test_split(indices_val_test, test_size = 0.5, random_state = 42)\n",
        "\n",
        "# slice the whole dataset by split indices, then convert to SparseTensor for later training\n",
        "def generate_edge(edge_indices: np.ndarray):\n",
        "  '''\n",
        "  Args:\n",
        "      edge_indices (np.ndarray): An array representing the indices of edges in the dataset.\n",
        "\n",
        "  Returns:\n",
        "      sub_edge_index (torch.Tensor): indices of edges in the specified subset.\n",
        "      edge_index_sparse (SparseTensor): A sparse tensor representing the adjacency matrix for the subset of edges.\n",
        "  '''\n",
        "  sub_edge_index = edge_index[:, edge_indices]\n",
        "  num_nodes = num_users + num_movies\n",
        "  edge_index_sparse = SparseTensor(row = sub_edge_index[0],\n",
        "                                   col = sub_edge_index[1],\n",
        "                                   sparse_sizes = (num_nodes, num_nodes))\n",
        "  return sub_edge_index, edge_index_sparse\n",
        "\n",
        "train_edge_index, train_sparse_edge_index = generate_edge(indices_train)\n",
        "val_edge_index, val_sparse_edge_index = generate_edge(indices_val)\n",
        "test_edge_index, test_sparse_edge_index = generate_edge(indices_test)"
      ],
      "metadata": {
        "id": "d9op9aVbTFIf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In training process, we will use mini-batch strategy and sample several positive edges and negative edges within each batch. A positive edge is defined as observed/training user-item interactions. During training, we want to penalize those negative edges by assigning larger loss to them. We will utilize the `structured_negative_sampling` function in PyG, which samples a negative edge for every positive edge in the graph, given by `edge_index`."
      ],
      "metadata": {
        "id": "tvZpaxT_aFCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "structured_negative_sampling samples a negative edge :obj:`(i,k)` for every positive edge :obj:`(i,j)` in the \n",
        "graph given by :attr:`edge_index`, and returns it as a tuple of the form :obj:`(i,j,k)`.\n",
        "'''\n",
        "edges = structured_negative_sampling(train_edge_index)\n",
        "edges = torch.stack(edges, dim=0)\n",
        "edges"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uxt8LxCnkE7",
        "outputId": "bcdcbf73-48d9-4056-ca03-ea148b39a1f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 408,  579,    2,  ...,  482,   15,  205],\n",
              "        [ 863,  990, 3734,  ..., 5729,  561,  621],\n",
              "        [1185, 2263, 1717,  ..., 3306, 5851,  531]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqKI1VduKcwf"
      },
      "source": [
        "# function which random samples a mini-batch of positive and negative samples\n",
        "def sample_mini_batch(batch_size, edge_index):\n",
        "    \"\"\"Randomly samples indices of a minibatch given an adjacency matrix\n",
        "\n",
        "    Args:\n",
        "        batch_size (int): minibatch size\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        tuple: user indices, positive item indices, negative item indices\n",
        "    \"\"\"\n",
        "    edges = structured_negative_sampling(edge_index)\n",
        "    edges = torch.stack(edges, dim=0)\n",
        "    indices = torch.randperm(edges.shape[1])[:batch_size]\n",
        "    batch = edges[:, indices]\n",
        "    user_indices, pos_item_indices, neg_item_indices = batch[0], batch[1], batch[2]\n",
        "    return user_indices, pos_item_indices, neg_item_indices"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Model Architecture"
      ],
      "metadata": {
        "id": "c6uMVxdDqUAT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOB5kDmtUrUY"
      },
      "source": [
        "## Light Graph Convolution\n",
        "Between each layer, LightGCN uses the following propagation rule for user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "e_u^{(k+1)} = \\sum_{i \\in N_u} \\frac{1}{\\sqrt{|N_u|}\\sqrt{|N_i|}} e_i^{(k)} \\quad e_i^{(k+1)} = \\sum_{u \\in N_i} \\frac{1}{\\sqrt{|N_i|}\\sqrt{|N_u|}} e_u^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$N_u$: the set of all neighbors of user $u$ (items liked by $u$)\n",
        "\n",
        "$N_i$: the set of all neighbors of item $i$ (users who liked $i$)\n",
        "\n",
        "$e_u^{(k)}$ : k-th layer user embedding\n",
        "\n",
        "$e_i^{(k)}$ : k-th layer item embedding\n",
        "\n",
        "\n",
        "\n",
        "## Layer Combination and Model Prediction\n",
        "The only trainable parameters of LightGCN are the 0-th layer embeddings $e_u^{(0)}$ and $e_i^{(0)}$ for each user and item. We combine the embeddings obtained at each layer of propagation to form the final embeddings for all user and item, $e_u$ and $e_i$ via the follwing equation.\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "e_u = \\sum_{k = 0}^K \\alpha_k e_u^{(k)} \\quad e_i = \\sum_{k = 0}^K \\alpha_k e_i^{(k)}\n",
        "\\end{equation}\n",
        "\n",
        "$\\alpha_k$ : hyperparameter which weights the contribution of the k-th layer embedding to the final embedding\n",
        "\n",
        "The model prediction is obtained by taking the inner product of the final user and item embeddings.\n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{y}_{ui} = e_u^Te_i\n",
        "\\end{equation}\n",
        "\n",
        "## Matrix Form\n",
        "In our implementation, we utilize the matrix form of LightGCN. We perform multi-scale diffusion to obtain the final embedding, which sums embeddings diffused across multi-hop scales. \n",
        "\n",
        "\\begin{equation}\n",
        "E^{(K)} = \\alpha_0 E^{(0)} + \\alpha_1 \\tilde{A}^1 E^{(0)} + \\alpha_2 \\tilde{A}^2 E^{(0)} + \\cdot \\cdot \\cdot + \\alpha_K \\tilde{A}^K \\tilde{A} E^{(0)}\n",
        "\\end{equation}\n",
        "\n",
        "$E^{(0)} \\in \\mathcal{R}^{(M + N)} \\times T$ : stacked initial item and user embeddings where $M$, $N$, and $T$ denote the number of users, number of items, and the dimension of each embedding respectively\n",
        "\n",
        "$\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$ : symmetrically normalized adjacency matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GvYg9ehDOX"
      },
      "source": [
        "# defines LightGCN model\n",
        "class LightGCN(MessagePassing):\n",
        "    \"\"\"LightGCN Model as proposed in https://arxiv.org/abs/2002.02126\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_users, num_items, embedding_dim=64, K=3, add_self_loops=False):\n",
        "        \"\"\"Initializes LightGCN Model\n",
        "\n",
        "        Args:\n",
        "            num_users (int): Number of users\n",
        "            num_items (int): Number of items\n",
        "            embedding_dim (int, optional): Dimensionality of embeddings. Defaults to 8.\n",
        "            K (int, optional): Number of message passing layers. Defaults to 3.\n",
        "            add_self_loops (bool, optional): Whether to add self loops for message passing. Defaults to False.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.num_users, self.num_items = num_users, num_items\n",
        "        self.embedding_dim, self.K = embedding_dim, K\n",
        "        self.add_self_loops = add_self_loops\n",
        "\n",
        "        self.users_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_users, embedding_dim=self.embedding_dim) # e_u^0\n",
        "        self.items_emb = nn.Embedding(\n",
        "            num_embeddings=self.num_items, embedding_dim=self.embedding_dim) # e_i^0\n",
        "\n",
        "        nn.init.normal_(self.users_emb.weight, std=0.1)\n",
        "        nn.init.normal_(self.items_emb.weight, std=0.1)\n",
        "\n",
        "    def forward(self, edge_index: SparseTensor):\n",
        "        \"\"\"Forward propagation of LightGCN Model.\n",
        "\n",
        "        Args:\n",
        "            edge_index (SparseTensor): adjacency matrix\n",
        "\n",
        "        Returns:\n",
        "            tuple (Tensor): e_u_k, e_u_0, e_i_k, e_i_0\n",
        "        \"\"\"\n",
        "        # compute \\tilde{A}: symmetrically normalized adjacency matrix\n",
        "        edge_index_norm = gcn_norm(\n",
        "            edge_index, add_self_loops=self.add_self_loops)\n",
        "\n",
        "        emb_0 = torch.cat([self.users_emb.weight, self.items_emb.weight]) # E^0\n",
        "        embs = [emb_0]\n",
        "        emb_k = emb_0\n",
        "\n",
        "        # multi-scale diffusion\n",
        "        for i in range(self.K):\n",
        "            emb_k = self.propagate(edge_index_norm, x=emb_k)\n",
        "            embs.append(emb_k)\n",
        "\n",
        "        embs = torch.stack(embs, dim=1)\n",
        "        emb_final = torch.mean(embs, dim=1) # E^K\n",
        "\n",
        "        users_emb_final, items_emb_final = torch.split(\n",
        "            emb_final, [self.num_users, self.num_items]) # splits into e_u^K and e_i^K\n",
        "\n",
        "        # returns e_u^K, e_u^0, e_i^K, e_i^0\n",
        "        return users_emb_final, self.users_emb.weight, items_emb_final, self.items_emb.weight\n",
        "\n",
        "    def message(self, x_j: Tensor) -> Tensor:\n",
        "        return x_j\n",
        "\n",
        "    def message_and_aggregate(self, adj_t: SparseTensor, x: Tensor) -> Tensor:\n",
        "        # computes \\tilde{A} @ x\n",
        "        return matmul(adj_t, x)\n",
        "\n",
        "model = LightGCN(num_users, num_movies)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "## Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} + \\lambda ||E^{(0)}||^2 \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n",
        "$\\lambda$: hyperparameter which controls the L2 regularization strength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "source": [
        "def bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, lambda_val):\n",
        "    \"\"\"Calculates Bayesian Personalized Ranking Loss (BPR) given the final and initial embeddings for users, positive items,\n",
        "       and negative items, as well as the L2 regularization strength lambda_val.\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): final embeddings for users\n",
        "        users_emb_0 (torch.Tensor): the initial embeddings for users\n",
        "        pos_items_emb_final (torch.Tensor): the final embeddings for positive items\n",
        "        pos_items_emb_0 (torch.Tensor): the initial embeddings for positive items\n",
        "        neg_items_emb_final (torch.Tensor): the final embeddings for negative items\n",
        "        neg_items_emb_0 (torch.Tensor): the initial embeddings for negative items\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: bpr loss value\n",
        "    \"\"\"\n",
        "    pos_scores = torch.sum(users_emb_final * pos_items_emb_final, dim=1) \n",
        "    neg_scores = torch.sum(users_emb_final * neg_items_emb_final, dim=1)\n",
        "    losses = -torch.log(torch.sigmoid(pos_scores - neg_scores))\n",
        "    loss = torch.mean(losses) + lambda_val * (torch.norm(users_emb_0) + torch.norm(pos_items_emb_0) + torch.norm(neg_items_emb_0))\n",
        "    return loss\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Evaluation Metrics"
      ],
      "metadata": {
        "id": "X-BrXDrgqt18"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7HVr3qLQGx"
      },
      "source": [
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "source": [
        "# helper function to get N_u\n",
        "def get_user_positive_items(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    user_pos_items = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        user = edge_index[0][i].item()\n",
        "        item = edge_index[1][i].item()\n",
        "        if user not in user_pos_items:\n",
        "            user_pos_items[user] = []\n",
        "        user_pos_items[user].append(item)\n",
        "    return user_pos_items"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8We4BTtfS4NV"
      },
      "source": [
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(r, dim=-1)  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor([len(groundTruth[i])\n",
        "                                  for i in range(len(groundTruth))])\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v4A3Ek4TE02"
      },
      "source": [
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1. / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1. / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.] = 1.\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.\n",
        "    return torch.mean(ndcg).item()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6_741LlTMwI"
      },
      "source": [
        "# wrapper function to get evaluation metrics\n",
        "def get_metrics(model, edge_index, exclude_edge_indices, k):\n",
        "    \"\"\"Computes the evaluation metrics: recall, precision, and ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    user_embedding = model.users_emb.weight\n",
        "    item_embedding = model.items_emb.weight\n",
        "\n",
        "    # get ratings between every user and item - shape is num users x num movies\n",
        "    rating = torch.matmul(user_embedding, item_embedding.T)\n",
        "\n",
        "    for exclude_edge_index in exclude_edge_indices:\n",
        "        # gets all the positive items for each user from the edge index\n",
        "        user_pos_items = get_user_positive_items(exclude_edge_index)\n",
        "        # get coordinates of all edges to exclude\n",
        "        exclude_users = []\n",
        "        exclude_items = []\n",
        "        for user, items in user_pos_items.items():\n",
        "            exclude_users.extend([user] * len(items))\n",
        "            exclude_items.extend(items)\n",
        "\n",
        "        # set ratings of excluded edges to large negative value\n",
        "        rating[exclude_users, exclude_items] = -(1 << 10)\n",
        "\n",
        "    # get the top k recommended items for each user\n",
        "    _, top_K_items = torch.topk(rating, k=k)\n",
        "\n",
        "    # get all unique users in evaluated split\n",
        "    users = edge_index[0].unique()\n",
        "\n",
        "    test_user_pos_items = get_user_positive_items(edge_index)\n",
        "\n",
        "    # convert test user pos items dictionary into a list\n",
        "    test_user_pos_items_list = [\n",
        "        test_user_pos_items[user.item()] for user in users]\n",
        "\n",
        "    # determine the correctness of topk predictions\n",
        "    r = []\n",
        "    for user in users:\n",
        "        ground_truth_items = test_user_pos_items[user.item()]\n",
        "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
        "        r.append(label)\n",
        "    r = torch.Tensor(np.array(r).astype('float'))\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "\n",
        "    return recall, precision, ndcg"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr_qESXASsVw"
      },
      "source": [
        "# wrapper function to evaluate model\n",
        "def evaluation(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "        lambda_val (float): determines lambda for bpr loss\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        sparse_edge_index)\n",
        "    edges = structured_negative_sampling(\n",
        "        edge_index, contains_neg_self_loops=False)\n",
        "    user_indices, pos_item_indices, neg_item_indices = edges[0], edges[1], edges[2]\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final, pos_items_emb_0,\n",
        "                    neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(\n",
        "        model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "## 5.Training Process\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "source": [
        "# define contants\n",
        "ITERATIONS = 1000\n",
        "BATCH_SIZE = 32\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 5\n",
        "LAMBDA = 1e-6"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49JDkBtKTfE-",
        "outputId": "fb5dd269-3e4f-4e5b-df5a-0856b7c12087"
      },
      "source": [
        "# setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cuda.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "0542f7b6-c372-4cdf-ef29-e03d30c5a1ab"
      },
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    # forward propagation\n",
        "    users_emb_final, users_emb_0, items_emb_final, items_emb_0 = model.forward(\n",
        "        train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        BATCH_SIZE, train_edge_index)\n",
        "    user_indices, pos_item_indices, neg_item_indices = user_indices.to(\n",
        "        device), pos_item_indices.to(device), neg_item_indices.to(device)\n",
        "    users_emb_final, users_emb_0 = users_emb_final[user_indices], users_emb_0[user_indices]\n",
        "    pos_items_emb_final, pos_items_emb_0 = items_emb_final[\n",
        "        pos_item_indices], items_emb_0[pos_item_indices]\n",
        "    neg_items_emb_final, neg_items_emb_0 = items_emb_final[\n",
        "        neg_item_indices], items_emb_0[neg_item_indices]\n",
        "\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(users_emb_final, users_emb_0, pos_items_emb_final,\n",
        "                          pos_items_emb_0, neg_items_emb_final, neg_items_emb_0, LAMBDA)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, precision, ndcg = evaluation(\n",
        "            model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n",
        "        print(f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\")\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Iteration 0/1000] train_loss: 0.69441, val_loss: 0.69337, val_recall@5: 0.00018, val_precision@5: 0.00071, val_ndcg@5: 0.00098\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-e9e35014a678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mITERS_PER_EVAL\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         val_loss, recall, precision, ndcg = evaluation(\n\u001b[0m\u001b[1;32m     32\u001b[0m             model, val_edge_index, val_sparse_edge_index, [train_edge_index], K, LAMBDA)\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-27e07b2a133c>\u001b[0m in \u001b[0;36mevaluation\u001b[0;34m(model, edge_index, sparse_edge_index, exclude_edge_indices, k, lambda_val)\u001b[0m\n\u001b[1;32m     29\u001b[0m                     neg_items_emb_final, neg_items_emb_0, lambda_val).item()\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     recall, precision, ndcg = get_metrics(\n\u001b[0m\u001b[1;32m     32\u001b[0m         model, edge_index, exclude_edge_indices, k)\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-21be7e8e02be>\u001b[0m in \u001b[0;36mget_metrics\u001b[0;34m(model, edge_index, exclude_edge_indices, k)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mground_truth_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_user_pos_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mground_truth_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_K_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-21be7e8e02be>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0muser\u001b[0m \u001b[0;32min\u001b[0m \u001b[0musers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mground_truth_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_user_pos_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mground_truth_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_K_items\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "nLcdvV5iXBSv",
        "outputId": "b4059176-24b0-46b5-ea65-68c2f9afd6d2"
      },
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6UjCTMQ_N5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d092d1-df05-4e7d-f2d9-5deead054d7c"
      },
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "            model, test_edge_index, test_sparse_edge_index, [train_edge_index, val_edge_index], K, LAMBDA)\n",
        "\n",
        "print(f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[test_loss: -51.9235, test_recall@20: 0.12543, test_precision@20: 0.04629, test_ndcg@20: 0.10125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "At4zWPfaVW6q"
      },
      "source": [
        "# Make New Recommendatios for a Given User"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzuMPxFVZlQn"
      },
      "source": [
        "model.eval()\n",
        "df = pd.read_csv(movie_path)\n",
        "movieid_title = pd.Series(df.title.values,index=df.movieId).to_dict()\n",
        "movieid_genres = pd.Series(df.genres.values,index=df.movieId).to_dict()\n",
        "\n",
        "user_pos_items = get_user_positive_items(edge_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(user_id, num_recs):\n",
        "    user = user_mapping[user_id]\n",
        "    e_u = model.users_emb.weight[user]\n",
        "    scores = model.items_emb.weight @ e_u\n",
        "\n",
        "    values, indices = torch.topk(scores, k=len(user_pos_items[user]) + num_recs)\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some movies that user {user_id} rated highly\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")\n",
        "\n",
        "    print()\n",
        "\n",
        "    movies = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
        "    movie_ids = [list(movie_mapping.keys())[list(movie_mapping.values()).index(movie)] for movie in movies]\n",
        "    titles = [movieid_title[id] for id in movie_ids]\n",
        "    genres = [movieid_genres[id] for id in movie_ids]\n",
        "\n",
        "    print(f\"Here are some suggested movies for user {user_id}\")\n",
        "    for i in range(num_recs):\n",
        "        print(f\"title: {titles[i]}, genres: {genres[i]} \")"
      ],
      "metadata": {
        "id": "oWR-LQUDaqgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSFgwnaecWBw",
        "outputId": "828828ac-78f5-47b2-9c72-ff8deff7b58f"
      },
      "source": [
        "USER_ID = 1\n",
        "NUM_RECS = 10\n",
        "\n",
        "make_predictions(USER_ID, NUM_RECS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are some movies that user 1 rated highly\n",
            "title: Forrest Gump (1994), genres: Comedy|Drama|Romance|War \n",
            "title: Matrix, The (1999), genres: Action|Sci-Fi|Thriller \n",
            "title: Silence of the Lambs, The (1991), genres: Crime|Horror|Thriller \n",
            "title: Star Wars: Episode IV - A New Hope (1977), genres: Action|Adventure|Sci-Fi \n",
            "title: Fight Club (1999), genres: Action|Crime|Drama|Thriller \n",
            "title: Schindler's List (1993), genres: Drama|War \n",
            "title: Star Wars: Episode V - The Empire Strikes Back (1980), genres: Action|Adventure|Sci-Fi \n",
            "title: Braveheart (1995), genres: Action|Drama|War \n",
            "title: Usual Suspects, The (1995), genres: Crime|Mystery|Thriller \n",
            "title: Star Wars: Episode VI - Return of the Jedi (1983), genres: Action|Adventure|Sci-Fi \n",
            "\n",
            "Here are some suggested movies for user 1\n",
            "title: Shawshank Redemption, The (1994), genres: Crime|Drama \n",
            "title: Pulp Fiction (1994), genres: Comedy|Crime|Drama|Thriller \n",
            "title: Godfather, The (1972), genres: Crime|Drama \n",
            "title: Terminator 2: Judgment Day (1991), genres: Action|Sci-Fi \n",
            "title: Lord of the Rings: The Return of the King, The (2003), genres: Action|Adventure|Drama|Fantasy \n",
            "title: Lord of the Rings: The Fellowship of the Ring, The (2001), genres: Adventure|Fantasy \n",
            "title: Sixth Sense, The (1999), genres: Drama|Horror|Mystery \n",
            "title: Lord of the Rings: The Two Towers, The (2002), genres: Adventure|Fantasy \n",
            "title: Apollo 13 (1995), genres: Adventure|Drama|IMAX \n",
            "title: Aladdin (1992), genres: Adventure|Animation|Children|Comedy|Musical \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLkRpNldrSQe"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}